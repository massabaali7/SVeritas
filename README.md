# Speaker Verification Benchmark Framework

A modular and extensible framework to benchmark **Speaker Verification** systems under clean and corrupted conditions with different models and augmentations.

---

## ğŸ“ Directory Structure

```bash
speaker-verification-benchmark/
â”œâ”€â”€ datasets/              # Dataset loaders (LibriSpeech, VoxCeleb, etc.)
â”‚   â”œâ”€â”€ build_data.py
â”‚   â”œâ”€â”€ tedlium.py
â”‚   â”œâ”€â”€ vctk.py
â”‚   â”œâ”€â”€ ami.py
â”‚   â”œâ”€â”€ librispeech.py
â”‚   â””â”€â”€ voxpopuli.py
â”œâ”€â”€ models/                # Speaker embedding models
â”‚   â”œâ”€â”€ ecapa2.py
â”‚   â”œâ”€â”€ ecapa_tdnn.py
â”‚   â”œâ”€â”€ redimnet.py
â”‚   â””â”€â”€ build_model.py
â”œâ”€â”€ corruptions/           # Audio corruptions & augmentations
â”‚   â”œâ”€â”€ echo.py
â”‚   â”œâ”€â”€ gain.py
â”‚   â”œâ”€â”€ pitch.py
â”‚   â”œâ”€â”€ rir.py
â”‚   â”œâ”€â”€ resample.py
â”‚   â”œâ”€â”€ filtering.py
â”‚   â”œâ”€â”€ speed.py
â”‚   â”œâ”€â”€ tempo.py
â”‚   â”œâ”€â”€ chorus.py
â”‚   â”œâ”€â”€ tremolo.py
â”‚   â”œâ”€â”€ tone.py
â”‚   â”œâ”€â”€ phaser.py
â”‚   â”œâ”€â”€ music.py
â”‚   â”œâ”€â”€ load_augmentations.py
â”‚   â””â”€â”€ build_aug.py
â”œâ”€â”€ utils/                 # Utility scripts
â”‚   â”œâ”€â”€ apply_rir.py
â”‚   â”œâ”€â”€ compute_snrs.py
â”‚   â””â”€â”€ load_audio.py
â”œâ”€â”€ evaluation/            # Metrics
â”‚   â”œâ”€â”€ eer.py
â”‚   â””â”€â”€ minDCF.py
â”œâ”€â”€ noise_data/            # External noises for augmentation
â”‚   â”œâ”€â”€ ms-snsd/
â”‚   â”œâ”€â”€ esc_dir/
â”‚   â”œâ”€â”€ wham_noise/
â”‚   â”œâ”€â”€ rir_noise/
â”‚   â””â”€â”€ musan/
â”œâ”€â”€ output_dir/            # Output samples or logs
â”‚   â””â”€â”€ samples/
â”œâ”€â”€ testing/               # Testing and simulation scripts
â”‚   â””â”€â”€ simulate_single_sample.py
â”œâ”€â”€ config/                # YAML configs
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md
```

# Speaker Verification Benchmark Framework

A modular and extensible framework for evaluating speaker verification systems under a variety of corruptions and model architectures.

## ğŸ”§ Structure

- `datasets/`: Load and configure datasets.
- `models/`: Pre-trained speaker embedding models.
- `corruptions/`: Augmentation and noise simulations.
- `utils/`: Common audio processing tools.
- `evaluation/`: Scoring functions (EER, minDCF).
- `testing/`: Sample simulation for debugging.
- `config/`: Configuration files.
- `main.py`: Main script for training/testing pipelines.

# ğŸ§© Installation
```bash
git clone https://github.com/massabaali7/SV_benchmark.git
cd speaker-verification-benchmark
pip install -r requirements.txt
```

# ğŸ“š How to Add a Dataset
```python
from datasets import load_dataset
import torch

class MyDataset(torch.nn.Module):
    def __init__(self, ...):
        super(MyDataset, self).__init__()
        # Init logic here

    def forward(self, audio):
        # Return dataset/audio
        pass
```

Add it to `build_dataset.py`:
```python
from .mydataset import MyDataset

def build_dataset(dataset_name, config, device):
    if dataset_name == 'MyDataset':
        return MyDataset(...)
    ...
```

# ğŸ§  Adding a Model
Create a new file in `models/`, e.g., `my_model.py`
```python
import torch

class MyModel(torch.nn.Module):
    def __init__(self, ...):
        super(MyModel, self).__init__()
        # Load or define model

    def forward(self, audio):
        # Return embeddings
        pass
```

Add it to `build_model.py`:
```python
from .my_model import MyModel

def build_model(model, config, device):
    if model == 'MyModel':
        return MyModel(...)
    ...
```

# ğŸ›ï¸ Adding an Augmentation
Create a new file in `corruptions/`, e.g., `my_aug.py`
```python
import torch

class MyAug(torch.nn.Module):
    def __init__(self, ...):
        super(MyAug, self).__init__()
        # Setup

    def forward(self, x):
        # Return augmented audio
        pass
```

Register in `build_aug.py`:
```python
from .my_aug import MyAug

def build_augmentation(simulate, config):
    if simulate == 'MyAug':
        return MyAug(...)
    ...
```
# Run simulation on a single sample
```python testing/simulate_single_sample.py --simulate 'echo' --waveform filename.wav ```
